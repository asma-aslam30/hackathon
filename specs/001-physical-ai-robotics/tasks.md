# Tasks: Physical AI & Humanoid Robotics Textbook

**Input**: Design documents from `/specs/001-physical-ai-robotics/`
**Prerequisites**: plan.md (required), spec.md (required for user stories)

**Tests**: This task breakdown focuses on hands-on exercises and mini-projects for student learning and does not explicitly include separate "test tasks" in a TDD sense, as the output of each task is itself a verifiable learning outcome or functional component.

**Organization**: Tasks are grouped by user story to enable independent implementation and testing of each story (representing the student's progressive learning journey).

## Format: `[ID] [P?] [Story] Description`

-   **[P]**: Can run in parallel (different files, no dependencies on incomplete tasks)
-   **[Story]**: Which user story this task belongs to (e.g., US1, US2, US3)
-   Include exact file paths in descriptions. For Docusaurus content, this refers to the conceptual markdown file path under `docs/`.

## Path Conventions

-   All Docusaurus content will reside under the `docs/` directory. Example paths will be `docs/intro/index.md`, `docs/module1/ros2-nodes.md`, etc.
-   ROS 2 Python code will be in a conceptual `robotics_ws/src/` directory.

---

## Phase 1: Setup (Shared Infrastructure)

**Purpose**: Initial project setup and environment configuration for the textbook development.

-   [X] T001 Create Docusaurus project structure in `/docs/`
    -   **Task Category**: Setup
    -   **Task Title**: Initialize Docusaurus Project
    -   **Task Description**: Create a new Docusaurus project in the `docs/` directory, ensuring it is ready for markdown content.
    -   **Software/Hardware Required**: Node.js, npm, Docusaurus CLI
    -   **Code Snippets or Example Commands**:
        ```bash
        npm init docusaurus@latest docs classic -- --typescript
        cd docs
        npm install
        npm start # Verify installation
        ```
    -   **Expected Output / Results**: A running Docusaurus development server accessible via browser, showing the default Docusaurus landing page.
    -   **Difficulty Level**: Beginner
    -   **Learning Outcomes**: Understand Docusaurus project initialization and local development server.
    -   **Mini-Challenges / Extensions**: Explore `docusaurus.config.ts` to change site title and favicon.
    -   **Cross-module Links**: Foundations for all subsequent chapter content generation.
    -   **Estimated Time to Complete**: 1 hour

-   [X] T002 Configure base Docusaurus navigation and sidebar in `docs/docusaurus.config.ts` and `docs/sidebars.ts`
    -   **Task Category**: Setup
    -   **Task Title**: Configure Docusaurus Navigation
    -   **Task Description**: Adjust the Docusaurus configuration to reflect the main sections of the "Physical AI & Humanoid Robotics" textbook and set up a preliminary sidebar structure. This will include creating `_category_.json` files for each chapter folder.
    -   **Software/Hardware Required**: Docusaurus project (from T001)
    -   **Code Snippets or Example Commands**:
        ```typescript
        // docs/docusaurus.config.ts (snippet)
        const config: Config = {
          title: 'Physical AI & Humanoid Robotics',
          tagline: 'Bridging the Digital and Physical Worlds',
          url: 'https://your-docusaurus-site.com',
          baseUrl: '/',
          // ...
          presets: [
            [
              'classic',
              {
                docs: {
                  sidebarPath: require.resolve('./sidebars.ts'),
                  // Please change this to your repo.
                  // Remove this to remove the "edit this page" links.
                  editUrl:
                    'https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/',
                },
                blog: {
                  showReadingTime: true,
                  // Please change this to your repo.
                  // Remove this to remove the "edit this page" links.
                  editUrl:
                    'https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/',
                },
                theme: {
                  customCss: require.resolve('./src/css/custom.css'),
                },
              },
            ],
          ],
          // ...
        };

        // docs/sidebars.ts (Conceptual - using autogenerated category.json)
        // No explicit sidebar entries for docs/docs/tutorial-extras, rely on _category_.json
        ```
        Create `docs/docs/tutorial-extras/_category_.json`:
        ```json
        {
          "label": "Tutorial Extras",
          "position": 3,
          "link": {
            "type": "generated-index",
            "title": "Tutorial Extras"
          }
        }
        ```
    -   **Expected Output / Results**: Docusaurus site with updated title and a sidebar showing at least "Tutorial Extras" or a similar root category.
    -   **Difficulty Level**: Beginner
    -   **Learning Outcomes**: Understand Docusaurus configuration for site metadata and navigation.
    -   **Mini-Challenges / Extensions**: Add custom links to the navbar.
    -   **Cross-module Links**: All chapters will rely on this navigation structure.
    -   **Estimated Time to Complete**: 1 hour

-   [X] T003 Create directory structure for all chapters in `docs/docs/`
    -   **Task Category**: Setup
    -   **Task Title**: Establish Chapter Directory Structure
    -   **Task Description**: Create the necessary subdirectories for each of the 12 chapters under `docs/docs/`, along with `_category_.json` files for each to enable Docusaurus's autogenerated sidebar.
    -   **Software/Hardware Required**: Docusaurus project
    -   **Code Snippets or Example Commands**:
        ```bash
        mkdir -p docs/docs/1-intro-physical-ai
        mkdir -p docs/docs/2-ros2-nervous-system
        mkdir -p docs/docs/3-digital-twin
        mkdir -p docs/docs/4-isaac-ai-brain
        mkdir -p docs/docs/5-vla-cognitive-robotics
        mkdir -p docs/docs/6-weekly-breakdown
        mkdir -p docs/docs/7-assessments
        mkdir -p docs/docs/8-hardware-requirements
        mkdir -p docs/docs/9-lab-architecture
        mkdir -p docs/docs/10-cloud-on-premise
        mkdir -p docs/docs/11-jetson-student-kit
        mkdir -p docs/docs/12-capstone-humanoid

        # Example _category_.json for Chapter 1
        echo '{\n  "label": "1. Introduction to Physical AI",\n  "position": 1,\n  "link": {\n    "type": "generated-index",\n    "title": "Introduction to Physical AI"\n  }\n}' > docs/docs/1-intro-physical-ai/_category_.json
        # ... repeat for all 12 chapters with appropriate labels and positions
        ```
    -   **Expected Output / Results**: Empty directories for each chapter and corresponding `_category_.json` files, which should update the Docusaurus sidebar with chapter titles.
    -   **Difficulty Level**: Beginner
    -   **Learning Outcomes**: Understand Docusaurus directory conventions and sidebar generation.
    -   **Mini-Challenges / Extensions**: Experiment with different `_category_.json` options (e.g., `type: "doc"` for a single entry).
    -   **Cross-module Links**: Provides the structure for all content.
    -   **Estimated Time to Complete**: 0.5 hours

---

## Phase 2: Foundational (Blocking Prerequisites)

**Purpose**: Core infrastructure and base content that MUST be complete before ANY user story (chapter content generation) can be fully implemented.

**‚ö†Ô∏è CRITICAL**: No user story work can begin until this phase is complete.

-   [X] T004 Create `docs/intro/index.md` for Chapter 1: Introduction to Physical AI
    -   **Task Category**: Content Generation
    -   **Task Title**: Generate Chapter 1 Content
    -   **Task Description**: Generate the full Docusaurus markdown content for "Chapter 1: Introduction to Physical AI," including the high-level overview, definitions, why it matters, core components, textbook journey, technical concepts, learning outcomes, mini-tasks, and Mermaid diagrams as per the content plan.
    -   **Software/Hardware Required**: Docusaurus project
    -   **Code Snippets or Example Commands**: (Content will be generated as markdown, no separate code commands for this step)
    -   **Expected Output / Results**: A `docs/docs/1-intro-physical-ai/index.md` file filled with the detailed content.
    -   **Difficulty Level**: Beginner
    -   **Learning Outcomes**: Comprehend the foundational aspects of Physical AI.
    -   **Mini-Challenges / Extensions**: Research a cutting-edge Physical AI application and write a short summary.
    -   **Cross-module Links**: Introduces all subsequent modules.
    -   **Estimated Time to Complete**: 2 hours

-   [X] T005 [P] Create `docs/docs/6-weekly-breakdown/index.md` for Chapter 6: Weekly Breakdown
    -   **Task Category**: Content Generation
    -   **Task Title**: Generate Chapter 6 (Weekly Breakdown) Content
    -   **Task Description**: Generate the full Docusaurus markdown content for "Chapter 6: Weekly Breakdown (Week 1‚Äì13)," including objectives, detailed weekly schedule with learning outcomes, labs, diagrams, code, simulation, hardware tasks, milestones, and critical path tasks.
    -   **Software/Hardware Required**: Docusaurus project
    -   **Code Snippets or Example Commands**: (Content will be generated as markdown)
    -   **Expected Output / Results**: A `docs/docs/6-weekly-breakdown/index.md` file filled with the detailed content.
    -   **Difficulty Level**: Intermediate
    -   **Learning Outcomes**: Understand the overall course structure and task dependencies.
    -   **Mini-Challenges / Extensions**: Propose an alternative 13-week schedule with justification.
    -   **Cross-module Links**: References all other chapters for scheduling.
    -   **Estimated Time to Complete**: 2.5 hours

-   [X] T006 [P] Create `docs/docs/7-assessments/index.md` for Chapter 7: Assessments
    -   **Task Category**: Content Generation
    -   **Task Title**: Generate Chapter 7 (Assessments) Content
    -   **Task Description**: Generate the full Docusaurus markdown content for "Chapter 7: Assessments," including purpose, quiz examples, coding challenges, simulation labs, hardware tasks, and the Capstone project evaluation rubric.
    -   **Software/Hardware Required**: Docusaurus project
    -   **Code Snippets or Example Commands**: (Content will be generated as markdown)
    -   **Expected Output / Results**: A `docs/docs/7-assessments/index.md` file filled with the detailed content.
    -   **Difficulty Level**: Intermediate
    -   **Learning Outcomes**: Comprehend how student progress will be evaluated.
    -   **Mini-Challenges / Extensions**: Design a new type of assessment for Physical AI.
    -   **Cross-module Links**: References all learning modules for assessment.
    -   **Estimated Time to Complete**: 1.5 hours

-   [X] T007 [P] Create `docs/docs/8-hardware-requirements/index.md` for Chapter 8: Hardware Requirements
    -   **Task Category**: Content Generation
    -   **Task Title**: Generate Chapter 8 (Hardware Requirements) Content
    -   **Task Description**: Generate the full Docusaurus markdown content for "Chapter 8: Hardware Requirements," detailing compute platforms (Desktop, Jetson), sensors (RealSense, IMU, LiDAR), actuators, robot platforms (Unitree, alternatives), and power systems.
    -   **Software/Hardware Required**: Docusaurus project
    -   **Code Snippets or Example Commands**: (Content will be generated as markdown)
    -   **Expected Output / Results**: A `docs/docs/8-hardware-requirements/index.md` file filled with the detailed content.
    -   **Difficulty Level**: Intermediate
    -   **Learning Outcomes**: Identify and understand the role of various robotics hardware components.
    -   **Mini-Challenges / Extensions**: Research a new emerging sensor technology for robotics.
    -   **Cross-module Links**: Essential for hardware labs in Chapters 11 and 12.
    -   **Estimated Time to Complete**: 2 hours

-   [X] T008 [P] Create `docs/docs/9-lab-architecture/index.md` for Chapter 9: Lab Architecture
    -   **Task Category**: Content Generation
    -   **Task Title**: Generate Chapter 9 (Lab Architecture) Content
    -   **Task Description**: Generate the full Docusaurus markdown content for "Chapter 9: Lab Architecture," covering local development environment setup, Docker, network architecture (ROS 2 discovery, SSH), and data management (`ros2 bag`).
    -   **Software/Hardware Required**: Docusaurus project
    -   **Code Snippets or Example Commands**: (Content will be generated as markdown)
    -   **Expected Output / Results**: A `docs/docs/9-lab-architecture/index.md` file filled with the detailed content.
    -   **Difficulty Level**: Intermediate
    -   **Learning Outcomes**: Design and set up a robust robotics development environment.
    -   **Mini-Challenges / Extensions**: Implement a basic CI/CD pipeline for a ROS 2 package.
    -   **Cross-module Links**: Supports development for all coding and simulation chapters.
    -   **Estimated Time to Complete**: 2 hours

-   [X] T009 [P] Create `docs/docs/10-cloud-on-premise/index.md` for Chapter 10: Cloud vs On-Premise Lab Setup
    -   **Task Category**: Content Generation
    -   **Task Title**: Generate Chapter 10 (Cloud vs On-Premise) Content
    -   **Task Description**: Generate the full Docusaurus markdown content for "Chapter 10: Cloud vs On-Premise Lab Setup," discussing advantages/disadvantages, hybrid approaches, and cloud robotics setup examples (AWS/GCP/Azure).
    -   **Software/Hardware Required**: Docusaurus project
    -   **Code Snippets or Example Commands**: (Content will be generated as markdown)
    -   **Expected Output / Results**: A `docs/docs/10-cloud-on-premise/index.md` file filled with the detailed content.
    -   **Difficulty Level**: Advanced
    -   **Learning Outcomes**: Understand trade-offs and strategies for cloud-augmented robotics.
    -   **Mini-Challenges / Extensions**: Deploy a simple ROS 2 node on a cloud VM.
    -   **Cross-module Links**: Relevant for scaling Chapters 4 and 5.
    -   **Estimated Time to Complete**: 1.5 hours

-   [X] T010 [P] Create `docs/docs/11-jetson-student-kit/index.md` for Chapter 11: The Economy Jetson Student Kit
    -   **Task Category**: Content Generation
    -   **Task Title**: Generate Chapter 11 (Jetson Student Kit) Content
    -   **Task Description**: Generate the full Docusaurus markdown content for "Chapter 11: The Economy Jetson Student Kit," detailing Jetson Orin Nano setup, essential sensors, actuation, simple robot platforms, and code optimization for Jetson.
    -   **Software/Hardware Required**: Docusaurus project
    -   **Code Snippets or Example Commands**: (Content will be generated as markdown)
    -   **Expected Output / Results**: A `docs/docs/11-jetson-student-kit/index.md` file filled with the detailed content.
    -   **Difficulty Level**: Intermediate
    -   **Learning Outcomes**: Build and program cost-effective physical AI systems on Jetson.
    -   **Mini-Challenges / Extensions**: Implement a basic object tracking system using RealSense on Jetson.
    -   **Cross-module Links**: Builds on Chapter 8, provides practical for Capstone.
    -   **Estimated Time to Complete**: 2 hours

-   [X] T011 Create `docs/docs/12-capstone-humanoid/index.md` for Chapter 12: Capstone: The Autonomous Humanoid
    -   **Task Category**: Content Generation
    -   **Task Title**: Generate Chapter 12 (Capstone) Content
    -   **Task Description**: Generate the full Docusaurus markdown content for "Chapter 12: Capstone: The Autonomous Humanoid," outlining the project goal, architecture review, module-by-module integration, testing, deployment, and future enhancements.
    -   **Software/Hardware Required**: Docusaurus project
    -   **Code Snippets or Example Commands**: (Content will be generated as markdown)
    -   **Expected Output / Results**: A `docs/docs/12-capstone-humanoid/index.md` file filled with the detailed content.
    -   **Difficulty Level**: Advanced
    -   **Learning Outcomes**: Design, implement, and integrate a complete autonomous humanoid.
    -   **Mini-Challenges / Extensions**: Add a new complex task for the humanoid.
    -   **Cross-module Links**: Integrates all previous modules.
    -   **Estimated Time to Complete**: 3 hours

**Checkpoint**: All foundational content and chapter overviews are now generated.

---

## Phase 3: User Story 1 - Comprehensive Learning Journey (Priority: P1) üéØ MVP

**Goal**: A beginner-to-intermediate AI/robotics student navigates the textbook, engaging with conceptual explanations, code examples, simulations, and hardware instructions to build a foundational understanding and progressively develop skills in Physical AI and Humanoid Robotics, culminating in the Capstone project.

**Independent Test**: A student can successfully complete a module, demonstrate understanding of its concepts, execute its code/simulations, and progress to the next module.

### Implementation for User Story 1 (Core Module Content)

-   [X] T012 [US1] Generate content for `docs/docs/2-ros2-nervous-system/index.md`
    -   **Task Category**: Content Generation
    -   **Task Title**: Generate Chapter 2 (ROS 2) Content
    -   **Task Description**: Generate full Docusaurus markdown for "Module 1: The Robotic Nervous System (ROS 2)," including ROS 2 setup, communication patterns (pub/sub, services, actions), launch files, TF2, Rviz2, code snippets, simulation exercises, learning outcomes, mini-tasks, and Mermaid diagrams.
    -   **Software/Hardware Required**: Docusaurus, ROS 2 Foxy/Humble
    -   **Code Snippets or Example Commands**:
        ```python
        # minimal_publisher.py
        import rclpy
        from rclpy.node import Node
        from std_msgs.msg import String

        class MinimalPublisher(Node):
            def __init__(self):
                super().__init__('minimal_publisher')
                self.publisher_ = self.create_publisher(String, 'topic', 10)
                timer_period = 0.5  # seconds
                self.timer = self.create_timer(timer_period, self.timer_callback)
                self.i = 0
            def timer_callback(self):
                msg = String()
                msg.data = 'Hello ROS 2: %d' % self.i
                self.publisher_.publish(msg)
                self.get_logger().info('Publishing: "%s"' % msg.data)
                self.i += 1
        def main(args=None):
            rclpy.init(args=args)
            minimal_publisher = MinimalPublisher()
            rclpy.spin(minimal_publisher)
            minimal_publisher.destroy_node()
            rclpy.shutdown()
        if __name__ == '__main__':
            main()
        ```
        ```bash
        # Simulation Exercise 2.1: Basic ROS 2 Communication Test
        ros2 run my_package minimal_publisher
        ros2 run my_package minimal_subscriber
        ros2 topic echo /topic
        ```
    -   **Expected Output / Results**: Complete markdown file. ROS 2 nodes publishing/subscribing, `ros2 topic echo` showing messages.
    -   **Difficulty Level**: Beginner
    -   **Learning Outcomes**: Implement basic ROS 2 communication.
    -   **Mini-Challenges / Extensions**: Create a custom message type.
    -   **Cross-module Links**: Foundation for Chapters 3, 4, 5, 12.
    -   **Estimated Time to Complete**: 6 hours

-   [X] T013 [US1] Generate content for `docs/docs/3-digital-twin/index.md`
    -   **Task Category**: Content Generation, Simulation
    -   **Task Title**: Generate Chapter 3 (Digital Twin) Content
    -   **Task Description**: Generate full Docusaurus markdown for "Module 2: The Digital Twin (Gazebo & Unity)," including introduction to digital twins, Gazebo fundamentals, ROS-Gazebo integration, Unity Robotics Hub, and comparison, with code, simulation exercises, learning outcomes, mini-tasks, and Mermaid diagrams.
    -   **Software/Hardware Required**: Docusaurus, ROS 2 Foxy/Humble, Gazebo, Unity Hub & Editor, `ros_gz_bridge`, ROS-TCP-Connector
    -   **Code Snippets or Example Commands**: (Examples from plan.md for ROS 2 controller, Unity message handler)
        ```bash
        # Simulation Exercise 3.1: Differential Drive Robot in Gazebo
        ros2 launch my_robot_gazebo spawn_robot.launch.py
        ros2 run my_robot_controller simple_controller
        ros2 topic pub /cmd_vel geometry_msgs/msg/Twist "{linear: {x: 0.2}, angular: {z: 0.0}}"
        ```
    -   **Expected Output / Results**: Complete markdown file. Simulated robot moving in Gazebo/Unity.
    -   **Difficulty Level**: Intermediate
    -   **Learning Outcomes**: Create and control simulated robots in Gazebo and Unity.
    -   **Mini-Challenges / Extensions**: Add a custom sensor to a Gazebo robot.
    -   **Cross-module Links**: Builds on Chapter 2, prepares for Chapters 4, 12.
    -   **Estimated Time to Complete**: 8 hours

-   [X] T014 [US1] Generate content for `docs/docs/4-isaac-ai-brain/index.md`
    -   **Task Category**: Content Generation, Simulation, AI
    -   **Task Title**: Generate Chapter 4 (NVIDIA Isaac) Content
    -   **Task Description**: Generate full Docusaurus markdown for "Module 3: The AI-Robot Brain (NVIDIA Isaac)," including Isaac Sim introduction, synthetic data generation, perception pipelines (Isaac ROS), and reinforcement learning, with code, simulation exercises, learning outcomes, mini-tasks, and Mermaid diagrams.
    -   **Software/Hardware Required**: Docusaurus, ROS 2 Foxy/Humble, NVIDIA Isaac Sim, Isaac ROS, Python (PyTorch/TensorFlow)
    -   **Code Snippets or Example Commands**: (Examples from plan.md for Isaac Replicator, Isaac ROS VSLAM launch, RL environment)
        ```bash
        # Simulation Exercise 4.2: Visual SLAM in Isaac Sim with Isaac ROS
        ros2 launch isaac_ros_vslam isaac_ros_vslam.launch.py image_topic:=/isaac_sim/camera/rgb map_frame:=map odom_frame:=odom
        rviz2
        ```
    -   **Expected Output / Results**: Complete markdown file. VSLAM tracking, synthetic data generated, RL agent training.
    -   **Difficulty Level**: Advanced
    -   **Learning Outcomes**: Utilize Isaac Sim for perception, RL, and synthetic data.
    -   **Mini-Challenges / Extensions**: Custom synthetic data generator.
    -   **Cross-module Links**: Builds on Chapter 2, complements Chapter 3, critical for Chapter 5, 12.
    -   **Estimated Time to Complete**: 10 hours

-   [X] T015 [US1] Generate content for `docs/docs/5-vla-cognitive-robotics/index.md`
    -   **Task Category**: Content Generation, AI, Integration
    -   **Task Title**: Generate Chapter 5 (VLA) Content
    -   **Task Description**: Generate full Docusaurus markdown for "Module 4: Vision-Language-Action (VLA)," covering VLA models, architecting a VLA pipeline, STT, LLM integration, visual grounding, action generation, with code, simulation exercises, learning outcomes, mini-tasks, and Mermaid diagrams.
    -   **Software/Hardware Required**: Docusaurus, ROS 2 Foxy/Humble, NVIDIA Isaac Sim, Python (LLM client libraries), API keys (LLM, STT)
    -   **Code Snippets or Example Commands**: (Examples from plan.md for Whisper node, LLM planner node, action executor)
        ```bash
        # Simulation Exercise 5.1: Voice Command to Robot Action (Simulated Humanoid)
        ros2 run vla_package whisper_node
        ros2 run vla_package llm_planner_node
        ros2 run vla_package action_executor_node
        echo "Robot, navigate to the blue cube." | ros2 topic pub /audio_in std_msgs/msg/String
        ```
    -   **Expected Output / Results**: Complete markdown file. Simulated humanoid responding to voice commands.
    -   **Difficulty Level**: Advanced
    -   **Learning Outcomes**: Implement a VLA pipeline for cognitive robotics.
    -   **Mini-Challenges / Extensions**: Define a new custom LLM tool for the robot.
    -   **Cross-module Links**: Integrates Chapters 2, 4, and 12.
    -   **Estimated Time to Complete**: 8 hours

**Checkpoint**: All core learning modules are now generated.

---

## Phase 4: User Story 2 - Advanced Skill Development (Priority: P2)

**Goal**: An advanced AI/robotics student seeks deep dives into specific technical areas like ROS2 control architecture, Isaac Sim perception pipelines, and VLA cognitive planning to enhance their existing expertise and apply advanced concepts to complex robotics challenges.

### Implementation for User Story 2 (Advanced Tasks within Modules)

-   [X] T016 [US2] Add advanced ROS 2 control architecture example to `docs/docs/2-ros2-nervous-system/index.md`
    -   **Task Category**: Coding, Integration
    -   **Task Title**: Advanced ROS 2 Control Architecture
    -   **Task Description**: Extend Chapter 2 content with a detailed example of `ros2_control` configuration and integration with a simulated robot, including controllers for joints and more complex topics like real-time considerations.
    -   **Software/Hardware Required**: ROS 2 Foxy/Humble, Gazebo, `ros2_control`
    -   **Code Snippets or Example Commands**: URDF snippet with `ros2_control` tag, example Python controller for position/velocity.
    -   **Expected Output / Results**: Enhanced markdown content.
    -   **Difficulty Level**: Advanced
    -   **Learning Outcomes**: Implement sophisticated ROS 2 robot control.
    -   **Mini-Challenges / Extensions**: Develop a custom `ros2_control` hardware interface.
    -   **Cross-module Links**: Builds on T012, supports Capstone (T011).
    -   **Estimated Time to Complete**: 4 hours

-   [X] T017 [US2] Add advanced Isaac Sim perception pipeline implementation to `docs/docs/4-isaac-ai-brain/index.md`
    -   **Task Category**: Simulation, AI
    -   **Task Title**: Advanced Isaac Sim Perception Pipeline
    -   **Task Description**: Extend Chapter 4 content with an advanced Isaac ROS perception pipeline example, such as multi-sensor fusion (e.g., camera + LiDAR data fusion for enhanced object detection or SLAM) using dedicated Isaac ROS packages.
    -   **Software/Hardware Required**: NVIDIA Isaac Sim, Isaac ROS, ROS 2 Foxy/Humble
    -   **Code Snippets or Example Commands**: Isaac ROS `launch.py` for sensor fusion, Python node for processing fused data.
    -   **Expected Output / Results**: Enhanced markdown content. Rviz2 visualization of fused sensor data and improved perception.
    -   **Difficulty Level**: Advanced
    -   **Learning Outcomes**: Design and implement multi-sensor perception systems.
    -   **Mini-Challenges / Extensions**: Implement a custom Isaac ROS node for a unique perception task.
    -   **Cross-module Links**: Builds on T014, critical for Capstone (T011).
    -   **Estimated Time to Complete**: 6 hours

-   [X] T018 [US2] Add VLA cognitive planning integration for complex scenarios to `docs/docs/5-vla-cognitive-robotics/index.md`
    -   **Task Category**: AI, Integration
    -   **Task Title**: Advanced VLA Cognitive Planning
    -   **Task Description**: Extend Chapter 5 content with advanced VLA cognitive planning scenarios for the simulated humanoid, including complex multi-step instructions, disambiguation strategies, and handling incomplete information from the LLM.
    -   **Software/Hardware Required**: NVIDIA Isaac Sim, ROS 2 Foxy/Humble, LLM APIs, Python
    -   **Code Snippets or Example Commands**: Python code for robust LLM prompt chaining, error handling for LLM function calls, context management for robot state.
    -   **Expected Output / Results**: Enhanced markdown content. Simulated humanoid executing more complex, nuanced voice commands.
    -   **Difficulty Level**: Advanced
    -   **Learning Outcomes**: Develop robust LLM-based planning for robotics.
    -   **Mini-Challenges / Extensions**: Implement learning from demonstration for new VLA tasks.
    -   **Cross-module Links**: Builds on T015, critical for Capstone (T011).
    -   **Estimated Time to Complete**: 6 hours

**Checkpoint**: Advanced topics within core modules are now covered.

---

## Phase 5: User Story 3 - Practical Hardware Application (Priority: P2)

**Goal**: A student aims to translate theoretical and simulated knowledge into practical hardware applications, specifically with Jetson Orin Nano/NX and supported robots, following detailed wiring and setup instructions.

### Implementation for User Story 3 (Hardware Integration Tasks)

-   [X] T019 [US3] Implement Jetson Orin Nano initial setup and basic software installation on a physical Jetson device.
    -   **Task Category**: Hardware, Setup
    -   **Task Title**: Jetson Orin Nano Initial Setup
    -   **Task Description**: Provide step-by-step instructions for flashing JetPack OS onto the Jetson Orin Nano, connecting essential peripherals, and performing initial system configuration. Install basic development tools and Python environment.
    -   **Software/Hardware Required**: NVIDIA Jetson Orin Nano Developer Kit, microSD card (64GB+), host PC (Ubuntu), JetPack SDK, power supply, monitor, keyboard, mouse.
    -   **Hardware Steps**:
        1.  Download and flash JetPack to microSD card using NVIDIA SDK Manager or Etcher.
        2.  Insert microSD card into Jetson.
        3.  Connect monitor, keyboard, mouse, and power supply.
        4.  Boot Jetson and complete initial Ubuntu setup.
        5.  Install `build-essential`, `cmake`, `git`, `python3-pip`.
    -   **Expected Output / Results**: A fully booted and configured Jetson Orin Nano running Ubuntu 22.04 with basic development tools installed.
    -   **Difficulty Level**: Beginner
    -   **Learning Outcomes**: Successfully set up an NVIDIA Jetson embedded system.
    -   **Mini-Challenges / Extensions**: Benchmark Jetson performance with a simple Python script.
    -   **Cross-module Links**: Builds on Chapter 8 & 11 (hardware context), prepares for hardware tasks in Capstone (T011).
    -   **Estimated Time to Complete**: 3 hours

-   [X] T020 [US3] Connect and integrate Intel RealSense D435i/D455 camera with Jetson via ROS 2.
    -   **Task Category**: Hardware, Integration
    -   **Task Title**: RealSense Camera Integration on Jetson
    -   **Task Description**: Provide detailed instructions for physically connecting the RealSense camera to the Jetson, installing the `librealsense` SDK, and integrating it with ROS 2 using the `ros2_realsense` package to stream RGB-D data.
    -   **Software/Hardware Required**: NVIDIA Jetson Orin Nano (from T019), Intel RealSense D435i/D455, USB 3.0 cable, ROS 2 Foxy/Humble, `librealsense` SDK, `ros2_realsense` package.
    -   **Hardware Steps**:
        1.  Physically connect RealSense camera to Jetson via USB 3.0 port.
        2.  Verify camera detection: `lsusb`.
        3.  Install `librealsense` SDK and `ros2_realsense` from source or binaries.
    -   **Code Snippets or Example Commands**:
        ```bash
        # Install librealsense (example commands)
        sudo apt-key adv --keyserver keys.gnupg.net --recv-key F6EAEB370
        echo "deb https://librealsense.intel.com/Debian/apt-repo $(lsb_release -cs) main" | sudo tee /etc/apt/sources.list.d/librealsense.list
        sudo apt update
        sudo apt install librealsense2-dkms librealsense2-utils librealsense2-dev

        # Build ros2_realsense (example)
        cd ~/ros2_ws/src
        git clone https://github.com/IntelRealSense/realsense-ros.git -b ros2-development
        cd ~/ros2_ws
        rosdep install --from-paths src --ignore-src -r -y
        colcon build --symlink-install --packages-select realsense2_camera

        # Launch RealSense ROS 2 node
        ros2 launch realsense2_camera rs_launch.py
        rviz2 # Visualize /camera/rgb/image_raw, /camera/depth/image_rect_raw, /camera/aligned_depth_to_color/image_raw, /camera/depth/color/points
        ```
    -   **Expected Output / Results**: RealSense camera detected, `ros2_realsense` node running, Rviz2 displaying live RGB and depth streams, and point clouds.
    -   **Difficulty Level**: Intermediate
    -   **Learning Outcomes**: Integrate a complex sensor with an embedded system using ROS 2.
    -   **Mini-Challenges / Extensions**: Calibrate the camera, experiment with different `rs_launch.py` parameters.
    -   **Cross-module Links**: Essential for perception in Capstone (T011), applies Chapter 8 & 11 concepts.
    -   **Estimated Time to Complete**: 4 hours

-   [X] T021 [US3] Interface BNO055 IMU with Jetson via I2C and publish data using a ROS 2 Python node.
    -   **Task Category**: Hardware, Coding
    -   **Task Title**: BNO055 IMU Integration on Jetson
    -   **Task Description**: Provide instructions for wiring the BNO055 IMU to the Jetson's I2C pins, enabling I2C on Jetson, writing a Python script to read IMU data (orientation, acceleration), and publishing it as a ROS 2 `Imu` message.
    -   **Software/Hardware Required**: NVIDIA Jetson Orin Nano (from T019), BNO055 IMU, breadboard, jumper wires, ROS 2 Foxy/Humble, Python `smbus2` (or similar I2C library).
    -   **Hardware Steps**:
        1.  Connect BNO055 VCC, GND, SDA, SCL pins to Jetson's corresponding GPIO pins (e.g., J41 header).
        2.  Enable I2C on Jetson (e.g., using `sudo i2cdetect -y 1`).
    -   **Code Snippets or Example Commands**:
        ```python
        # bno055_imu_node.py (conceptual)
        import rclpy
        from rclpy.node import Node
        from sensor_msgs.msg import Imu
        import smbus2 # Example I2C library
        import time

        # BNO055 I2C address and registers (simplified for example)
        BNO055_ADDRESS_A = 0x28
        BNO055_CHIP_ID_ADDR = 0x00
        # ... other register definitions ...

        class BNO055IMUNode(Node):
            def __init__(self):
                super().__init__('bno055_imu_node')
                self.publisher_ = self.create_publisher(Imu, 'imu/data', 10)
                self.bus = smbus2.SMBus(1) # I2C bus 1 on Jetson
                # ... BNO055 initialization and configuration ...
                self.timer = self.create_timer(0.01, self.timer_callback) # 100 Hz
                self.get_logger().info("BNO055 IMU Node Started")

            def read_imu_data(self):
                # ... read raw data from BNO055 registers ...
                # ... convert to appropriate units ...
                # ... create and populate Imu message ...
                msg = Imu()
                msg.header.stamp = self.get_clock().now().to_msg()
                msg.header.frame_id = 'imu_link'
                # Example: fill orientation (quaternion), angular_velocity, linear_acceleration
                # msg.orientation.x = ...
                # msg.angular_velocity.x = ...
                # msg.linear_acceleration.x = ...
                return msg

            def timer_callback(self):
                imu_msg = self.read_imu_data()
                self.publisher_.publish(imu_msg)

        def main(args=None):
            rclpy.init(args=args)
            node = BNO055IMUNode()
            rclpy.spin(node)
            node.destroy_node()
            rclpy.shutdown()

        if __name__ == '__main__':
            main()
        ```
    -   **Expected Output / Results**: `bno055_imu_node` running on Jetson, `ros2 topic echo /imu/data` displaying live IMU messages (orientation, acceleration).
    -   **Difficulty Level**: Intermediate
    -   **Learning Outcomes**: Programmatically interface with sensors via I2C/UART on embedded Linux, publish sensor data in ROS 2.
    -   **Mini-Challenges / Extensions**: Implement sensor fusion for improved orientation using an Extended Kalman Filter (EKF) on the Jetson.
    -   **Cross-module Links**: Essential for localization/state estimation in Capstone (T011), applies Chapter 8 & 11 concepts.
    -   **Estimated Time to Complete**: 5 hours

-   [X] T022 [US3] Build a simple differential drive mobile robot platform and control it via ROS 2 on Jetson.
    -   **Task Category**: Hardware, Integration, Coding
    -   **Task Title**: DIY Mobile Robot Platform Construction & Control
    -   **Task Description**: Provide instructions for constructing a basic differential drive mobile robot chassis (e.g., using 3D printed parts or off-the-shelf components), wiring DC motors to a motor driver (e.g., L298N), and writing a ROS 2 Python node on Jetson to receive `Twist` commands and control the motors.
    -   **Software/Hardware Required**: NVIDIA Jetson Orin Nano (from T019), DC motors (x2), motor driver (L298N or similar), mobile robot chassis components, wheels, power supply/LiPo battery, breadboard, jumper wires, ROS 2 Foxy/Humble, Python `RPi.GPIO` (or similar for Jetson GPIO).
    -   **Hardware Steps**:
        1.  Assemble chassis, attach motors.
        2.  Wire motor driver to Jetson GPIO pins (for PWM/direction control) and to motors.
        3.  Connect motor driver to power supply/battery.
    -   **Code Snippets or Example Commands**:
        ```python
        # differential_drive_controller_node.py (conceptual, building on Chapter 11 example)
        import rclpy
        from rclpy.node import Node
        from geometry_msgs.msg import Twist
        import RPi.GPIO as GPIO # For Jetson GPIO
        import time

        # Define GPIO pins for motor driver (simplified)
        LEFT_PWM_PIN = 12
        LEFT_DIR_PIN = 16
        RIGHT_PWM_PIN = 13
        RIGHT_DIR_PIN = 19

        class DifferentialDriveController(Node):
            def __init__(self):
                super().__init__('diff_drive_controller')
                self.subscription = self.create_subscription(
                    Twist,
                    '/cmd_vel',
                    self.cmd_vel_callback,
                    10
                )
                # ... GPIO setup (setmode, setup pins, PWM objects) ...
                self.get_logger().info('Differential Drive Controller Node Started')

            def cmd_vel_callback(self, msg: Twist):
                linear_x = msg.linear.x
                angular_z = msg.angular.z
                # Implement kinematics: convert linear_x, angular_z to left/right wheel speeds
                # ... set motor directions and PWM values via GPIO ...
                self.get_logger().info(f'Controlling motors: linear={linear_x:.2f}, angular={angular_z:.2f}')

            # ... add function for graceful GPIO cleanup on shutdown ...

        def main(args=None):
            rclpy.init(args=args)
            node = DifferentialDriveController()
            rclpy.spin(node)
            node.destroy_node()
            rclpy.shutdown()
            GPIO.cleanup() # Ensure GPIO cleanup

        if __name__ == '__main__':
            main()
        ```
        ```bash
        # Control robot via teleop
        ros2 run teleop_twist_keyboard teleop_twist_keyboard cmd_vel:=/cmd_vel
        ```
    -   **Expected Output / Results**: Physical robot motors respond to `Twist` commands from ROS 2, moving the robot as expected.
    -   **Difficulty Level**: Intermediate
    -   **Learning Outcomes**: Build a basic mobile robot, control actuators via embedded system GPIO, implement ROS 2 control nodes for locomotion.
    -   **Mini-Challenges / Extensions**: Add odometry feedback from motor encoders and publish `Odometry` messages. Implement a simple line-following behavior.
    -   **Cross-module Links**: Applies Chapter 2 (ROS 2), Chapter 8 & 11 (hardware), provides locomotion for Capstone (T011).
    -   **Estimated Time to Complete**: 6 hours

**Checkpoint**: Practical hardware application skills on Jetson are now covered.

---

## Phase 6: Polish & Cross-Cutting Concerns

**Purpose**: Improvements that affect multiple user stories (chapter content), ensuring overall quality, consistency, and Docusaurus readiness.

-   [X] T023 [P] Review and standardize Docusaurus front matter for all chapter markdown files (`docs/docs/**/index.md`)
    -   **Task Category**: Documentation, Formatting
    -   **Task Title**: Standardize Docusaurus Front Matter
    -   **Task Description**: Go through all generated chapter markdown files and ensure consistent Docusaurus front matter (`id`, `title`, `sidebar_label`) for proper rendering and navigation. Adjust `_category_.json` files if necessary.
    -   **Software/Hardware Required**: Docusaurus project
    -   **Code Snippets or Example Commands**: (Manual file editing)
    -   **Expected Output / Results**: All chapter pages render correctly in Docusaurus with proper titles and sidebar labels.
    -   **Difficulty Level**: Beginner
    -   **Learning Outcomes**: Master Docusaurus front matter for content organization.
    -   **Mini-Challenges / Extensions**: Add custom metadata fields to front matter.
    -   **Cross-module Links**: Affects all chapters.
    -   **Estimated Time to Complete**: 1 hour

-   [X] T024 [P] Verify all Mermaid diagrams render correctly and are consistent across chapters
    -   **Task Category**: Documentation, Visualization
    -   **Task Title**: Validate Mermaid Diagram Rendering
    -   **Task Description**: Review all generated content for Mermaid diagrams. Verify that their syntax is correct and they render as expected in the Docusaurus environment. Make necessary corrections.
    -   **Software/Hardware Required**: Docusaurus project, browser
    -   **Code Snippets or Example Commands**: (Manual syntax checking/correction)
    -   **Expected Output / Results**: All Mermaid diagrams correctly displayed throughout the textbook.
    -   **Difficulty Level**: Beginner
    -   **Learning Outcomes**: Understand and troubleshoot Mermaid syntax.
    -   **Mini-Challenges / Extensions**: Design a new Mermaid diagram for an aspect not yet covered.
    -   **Cross-module Links**: Affects all chapters with diagrams.
    -   **Estimated Time to Complete**: 1.5 hours

-   [X] T025 [P] Implement Docusaurus search functionality and test its efficacy for finding keywords
    -   **Task Category**: Documentation, Usability
    -   **Task Title**: Integrate Docusaurus Search
    -   **Task Description**: Integrate a search solution into the Docusaurus project (e.g., Algolia DocSearch or a local search plugin) and verify that students can effectively search for technical concepts, chapter titles, and task descriptions.
    -   **Software/Hardware Required**: Docusaurus project
    -   **Code Snippets or Example Commands**: (Docusaurus plugin installation and configuration)
        ```bash
        # Example for local search plugin
        npm install @easyops-cn/docusaurus-search-local
        # Add to docusaurus.config.ts plugins section
        ```
    -   **Expected Output / Results**: A functional search bar on the Docusaurus site that returns relevant results.
    -   **Difficulty Level**: Intermediate
    -   **Learning Outcomes**: Enhance user experience in documentation.
    -   **Mini-Challenges / Extensions**: Customize search result display.
    -   **Cross-module Links**: Improves accessibility for all content.
    -   **Estimated Time to Complete**: 2 hours

-   [X] T026 Review all code snippets for formatting, syntax, and `rclpy` adherence
    -   **Task Category**: Coding, Quality Assurance
    -   **Task Title**: Code Snippet Review & Validation
    -   **Task Description**: Go through all `ROS2 Python (rclpy)` code snippets across all chapters. Verify syntax correctness, proper indentation, `rclpy` best practices, and consistency in variable naming. Ensure they are directly usable.
    -   **Software/Hardware Required**: Python IDE, ROS 2 Foxy/Humble development environment
    -   **Code Snippets or Example Commands**: (Manual code review and potential execution for verification)
    -   **Expected Output / Results**: All code snippets are high quality, error-free, and follow best practices.
    -   **Difficulty Level**: Intermediate
    -   **Learning Outcomes**: Develop strong code review and quality assurance skills.
    -   **Mini-Challenges / Extensions**: Write unit tests for some of the provided utility code snippets (if any).
    -   **Cross-module Links**: Affects all coding tasks.
    -   **Estimated Time to Complete**: 4 hours

-   [X] T027 Conduct a final review of all content for clarity, technical accuracy, and adherence to tone and style.
    -   **Task Category**: Content Quality, Review
    -   **Task Title**: Comprehensive Content Quality Review
    -   **Task Description**: Perform a final pass on the entire textbook content. Check for clarity, grammar, spelling, technical accuracy, consistency in terminology, and adherence to the specified academic and highly technical tone and style.
    -   **Software/Hardware Required**: Browser, markdown editor
    -   **Code Snippets or Example Commands**: (Manual review)
    -   **Expected Output / Results**: A polished, error-free, and high-quality textbook.
    -   **Difficulty Level**: Beginner
    -   **Learning Outcomes**: Improve content review and editing skills.
    -   **Mini-Challenges / Extensions**: Get a peer review for the content.
    -   **Cross-module Links**: Overall quality assurance.
    -   **Estimated Time to Complete**: 6 hours

---

## Dependencies & Execution Order

### Phase Dependencies

-   **Setup (Phase 1)**: No dependencies - can start immediately.
-   **Foundational (Phase 2)**: Depends on Setup completion - BLOCKS all user stories.
-   **User Stories (Phase 3+)**: All depend on Foundational phase completion.
    -   User stories can then proceed in parallel (if staffed).
    -   Or sequentially in priority order (P1 ‚Üí P2 ‚Üí P3).
-   **Polish (Final Phase)**: Depends on all desired user stories being complete.

### User Story Dependencies

-   **User Story 1 (P1 - Comprehensive Learning Journey)**: Can start after Foundational (Phase 2) - No dependencies on other stories for its core.
-   **User Story 2 (P2 - Advanced Skill Development)**: Can start after Foundational (Phase 2) - Integrates with and builds on User Story 1 content. It is recommended to complete US1 tasks before US2 tasks within specific modules.
-   **User Story 3 (P2 - Practical Hardware Application)**: Can start after Foundational (Phase 2) - Integrates with and builds on User Story 1 (ROS 2, basic simulation) and relies on concepts from Hardware Requirements (T007) and Jetson Student Kit (T010).

### Within Each User Story / Phase

-   Tasks should generally flow from conceptual content generation to coding, simulation, and hardware integration.
-   For content generation tasks, ensure a coherent narrative.
-   For practical tasks, setup/installation often precedes coding/execution.

### Parallel Opportunities

-   All tasks within Phase 1 (Setup) are parallelizable.
-   Tasks T005, T006, T007, T008, T009, T010 within Phase 2 (Foundational) are parallelizable as they are independent chapter content generations.
-   Once Foundational phase completes, User Story 1, 2, and 3 tasks *could* be worked on in parallel by different "students" or "developers" if the learning path or team capacity allows, respecting their internal dependencies.
-   Tasks within the "Polish & Cross-Cutting Concerns" phase are largely parallelizable.

---

## Implementation Strategy

### MVP First (Core Learning Modules)

1.  Complete Phase 1: Setup (T001, T002, T003).
2.  Complete Phase 2: Foundational (T004-T011). This delivers the initial overview and structure of the entire textbook.
3.  Complete Phase 3: User Story 1 (T012-T015). This delivers the core learning modules (ROS 2, Digital Twin, Isaac, VLA).
4.  **STOP and VALIDATE**: Ensure a student can successfully complete these core modules and progress.
5.  Publish/demo this core learning path.

### Incremental Delivery

1.  Complete Setup + Foundational ‚Üí Foundation ready.
2.  Add User Story 1 ‚Üí Core learning path ready.
3.  Add User Story 2 ‚Üí Advanced skills integrated within core modules.
4.  Add User Story 3 ‚Üí Practical hardware application content available.
5.  Each story adds value without breaking previous content.
6.  Complete Final Phase: Polish & Cross-Cutting Concerns.

### Parallel Team Strategy (Conceptual for multi-person content development)

With multiple content developers:

1.  Team completes Setup + Foundational together.
2.  Once Foundational is done:
    -   Developer A: Focuses on User Story 1 content (T012-T015).
    -   Developer B: Focuses on User Story 2 content (T016-T018).
    -   Developer C: Focuses on User Story 3 content (T019-T022).
3.  Finally, the team collaboratively tackles Phase 6: Polish & Cross-Cutting Concerns (T023-T027).

---

## Notes

-   [P] tasks = different files, no dependencies.
-   [Story] label maps task to specific user story for traceability.
-   Each user story should be independently completable and testable in terms of learning outcomes.
-   The "Estimated Time to Complete" is a guideline for content generation and student effort.
-   The Capstone project is implicitly built throughout by integrating knowledge from preceding modules and will be explicitly detailed in its own chapter.
-   Avoid: vague tasks, same file conflicts, cross-story dependencies that break independence.
