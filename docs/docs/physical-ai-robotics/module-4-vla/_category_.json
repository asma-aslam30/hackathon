{
  "label": "Module 4: Vision-Language-Action (VLA)",
  "position": 4,
  "link": {
    "type": "generated-index",
    "description": "Focus: The convergence of LLMs and Robotics. Voice-to-Action using OpenAI Whisper for voice commands, Cognitive Planning using LLMs to translate natural language into ROS 2 actions, and the capstone Autonomous Humanoid project."
  }
}